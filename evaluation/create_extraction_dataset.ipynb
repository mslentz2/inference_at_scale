{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice using an LLM for Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from datasets import load_dataset\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    ")\n",
    "\n",
    "from azure.identity import AzureAuthorityHosts\n",
    "from azure.keyvault.secrets import SecretClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your Azure OpenAI Resource and Key Vault\n",
    "\n",
    "_If you have your resource from the last exercise, you don't need to complete the following steps._\n",
    "\n",
    "Navigate to the [Azure Portal](https://portal.azure.com/#home) or [US Gov Azure Portal](https://portal.azure.us/#home) and login using your account. Next you're going to create an Azure OpenAI resource, create a new resource group and use any unique name for the resource's name.  \n",
    "Once the resource is created, you need to open [Azure AI Foundry](https://ai.azure.com/) or [Azure OpenAI Studio](https://ai.azure.us/) to deploy the model. Navigate to deployments, press deploy model and select gpt-4o-mini.  Make sure to increase your rate limit, or tokens per minute (around 700k should be sufficient)\n",
    "\n",
    "Once that is created, copy the key (Found under Resource Management > Keys and Endpoints) and create a new key vault. Assign the same resource group as your Azure OpenAI resource and again pick a unique name for the key vault name.  \n",
    "\n",
    "Once the key vault is created, make a new secret with the API key.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Azure OpenAI\n",
    "First, run `az login` in the terminal and login to your FedAIRS account.  \n",
    "<br>\n",
    "If you are using a Gov account:<br>\n",
    "az cloud set --name AzureUSGovernment <br>\n",
    "az login <br>\n",
    "az account set --subscription=\"your subscription\"<br>\n",
    "\n",
    "If you are using a commercial account:<br>\n",
    "az login <br>\n",
    "az account set --subscription=\"your subscription\"<br>\n",
    "<br>\n",
    "Two things are needed to connect to your Azure OpenAI resource\n",
    "- Your API key\n",
    "- Your Endpoint  \n",
    "  \n",
    "For the API Key, we are going to connect to the key vault we just made to insert the key. For this, you'll need to change the URL below to match your key vault's URL.  \n",
    "Next, we will insert the endpoint URL from our Azure OpenAI resource.\n",
    "\n",
    "Our `azure_client` is where we are calling the LLM and connecting to the model we deployed. Other parameters can be passed in, like timeout or max_retires.\n",
    "\n",
    "Note: In the block below we inserted `credential = DefaultAzureCredential(authority=AzureAuthorityHosts.AZURE_GOVERNMENT)`. This is because when we use our FedAIRS account we are connected to the US Government cloud, rather than the regular commercial cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "credential = DefaultAzureCredential(authority=AzureAuthorityHosts.AZURE_GOVERNMENT)\n",
    "\n",
    "secret_client = SecretClient(vault_url=os.getenv('KEY_VAULT_URL'), credential=credential)\n",
    "deployment = os.getenv('DEPLOYMENT')\n",
    "endpoint_url = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "api_version = os.getenv('API_VERSION')\n",
    "api_key = secret_client.get_secret(os.getenv('SECRET_NAME')).value\n",
    "\n",
    "\n",
    "azure_client = AzureChatOpenAI(\n",
    "                api_key=api_key\n",
    "                ,api_version=api_version\n",
    "                ,azure_endpoint=endpoint_url\n",
    "                ,deployment_name=deployment\n",
    "                ,temperature=0\n",
    "                ,max_tokens=4000\n",
    "                ,model_kwargs={\"response_format\": {\"type\": \"json_object\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "The dataset we are looking at is about 300 rows of sample data about different employees. Each employee has maany attributes but for this exercise we will only use:  \n",
    "* FirstName\n",
    "* LastName\n",
    "* Title\n",
    "* BirthDate\n",
    "* EmailAddress\n",
    "* DepartmentName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = pd.read_csv('./data/DimEmployee.csv')\n",
    "employees.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the previous exercises, we are going to take a sample of 100 employees and convert that into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_sample = employees.sample(100).reset_index()\n",
    "employees_sample_array = employees_sample.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Narrative\n",
    "\n",
    "We are going to prompt the LLM with the 6 attributes mentioned before (FirstName LastName, Title, BirthDate, EmailAddress, DepartmentName) and ask it to create a story based on these facts. We will instruct the LLM to keep the spelling and details of all the infomation passed intact, but still create a narrative in the style requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_prompt = PromptTemplate.from_template(\n",
    "\n",
    "template = '''\n",
    "### Instructions:\n",
    "Your task is to create a four-sentence story in a Shakespearean style for the following attributes of each employee: FirstName, LastName, Title, BirthDate, EmailAddress, DepartmentName. You must include all of the details given and all details of the employee should remain intact, there should be no spelling or details about the employee changed.\n",
    "Each story should capture the essence of the employee's life and their role within the company, based solely on the information provided. Do not introduce any additional details beyond what is given in the input.\n",
    "\n",
    "### Reasoning Required:\n",
    "After crafting your Shakespearean tale, provide a brief explanation (about 50 words) of why you chose to depict the employee in this particular way. Analyze how Shakespearean techniques enhance the storytelling and relate to the employee's modern workplace experiences.\n",
    "\n",
    "### Employee Details:\n",
    "FirstName: {FirstName}\n",
    "LastName: {LastName}\n",
    "Title: {Title}\n",
    "BirthDate: {BirthDate}\n",
    "EmailAddress: {EmailAddress}\n",
    "DepartmentName: {DepartmentName}\n",
    "\n",
    "### Return JSON:\n",
    "{{\n",
    "    \"ShakespeareStory\": \"<The four sentence story about this employee in Shakespearean style>\"\n",
    "    \"ShakespeareReasoning\": \"<Explain why you chose to craft this employee's story in this way>\"\n",
    "}}\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_chain = (\n",
    "    shakespeare_prompt\n",
    "    | azure_client\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_prompt = PromptTemplate.from_template(\n",
    "\n",
    "template = '''\n",
    "### Instructions:\n",
    "Your task is to create a four-sentence story in the style of the Marvel Comic Books for the following attributes of each employee: FirstName, LastName, Title, BirthDate, EmailAddress, DepartmentName. You must include all of the details given and all details of the employee should remain intact, there should be no spelling or details about the employee changed.\n",
    "Each story should capture the essence of the employee's life and their role within the company, based solely on the information provided. Do not introduce any additional details beyond what is given in the input.\n",
    "\n",
    "### Reasoning Required:\n",
    "After crafting your Shakespearean tale, provide a brief explanation (about 50 words) of why you chose to depict the employee in this particular way. Analyze how Shakespearean techniques enhance the storytelling and relate to the employee's modern workplace experiences.\n",
    "\n",
    "\n",
    "### Employee Details:\n",
    "FirstName: {FirstName}\n",
    "LastName: {LastName}\n",
    "Title: {Title}\n",
    "BirthDate: {BirthDate}\n",
    "EmailAddress: {EmailAddress}\n",
    "DepartmentName: {DepartmentName}\n",
    "\n",
    "\n",
    "### Return JSON:\n",
    "{{\n",
    "    \"MarvelStory\": \"<The four sentence story about this employee in the Marvel Comics style>\"\n",
    "    \"MarvelReasoning\": \"<Explain why you chose to craft this employee's story in this way>\"\n",
    "}}\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvel_chain = (\n",
    "    marvel_prompt\n",
    "    | azure_client\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairytale_prompt = PromptTemplate.from_template(\n",
    "\n",
    "template = '''\n",
    "### Instructions:\n",
    "Your task is to create a four-sentence story in the style of a traditional fairy-tale for the following attributes of each employee: FirstName, LastName, Title, BirthDate, EmailAddress, DepartmentName. You must include all of the details given and all details of the employee should remain intact, there should be no spelling or details about the employee changed.\n",
    "Each story should capture the essence of the employee's life and their role within the company, based solely on the information provided. Do not introduce any additional details beyond what is given in the input.\n",
    "\n",
    "### Reasoning Required:\n",
    "After crafting your Shakespearean tale, provide a brief explanation (about 50 words) of why you chose to depict the employee in this particular way. Analyze how Shakespearean techniques enhance the storytelling and relate to the employee's modern workplace experiences.\n",
    "\n",
    "\n",
    "### Employee Details:\n",
    "FirstName: {FirstName}\n",
    "LastName: {LastName}\n",
    "Title: {Title}\n",
    "BirthDate: {BirthDate}\n",
    "EmailAddress: {EmailAddress}\n",
    "DepartmentName: {DepartmentName}\n",
    "\n",
    "\n",
    "### Return JSON:\n",
    "{{\n",
    "    \"FairyTaleStory\": \"<The four sentence story about this employee in the fairytale  style>\"\n",
    "    \"FairyTaleReasoning\": \"<Explain why you chose to craft this employee's story in this way>\"\n",
    "}}\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairytale_chain = (\n",
    "    fairytale_prompt\n",
    "    | azure_client\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def runChain(employee_array, chain):\n",
    "    texts = [{\"FirstName\": x[3], \"LastName\": x[4], \"Title\": x[5], \"BirthDate\": x[7], \"EmailAddress\": x[8], \"DepartmentName\": x[16]} for x in employee_array]\n",
    "    return await chain.abatch(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def assess_summaries(df, array, chain):\n",
    "    results = await runChain(array, chain)\n",
    "    df[\"results\"] = results\n",
    "\n",
    "    results_df = pd.json_normalize(df.results.apply(json.loads))\n",
    "    output = pd.concat([df, results_df], axis=1)\n",
    "    output.drop(columns='results', inplace=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are running the prompts through the LLM and adding all of the stories to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = employees_sample\n",
    "input_array = employees_sample_array\n",
    "chains = [shakespeare_chain, marvel_chain, fairytale_chain]\n",
    "output_df = None\n",
    "\n",
    "for chain in chains:\n",
    "    print(chain)\n",
    "    output_df = await assess_summaries(input_df, input_array, chain)\n",
    "    input_df = output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will save the dataframe into a CSV to be used in the extraction notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(\"DimEmployeeStories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
