{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### This notebook takes a small dataset of reviews about a service and performs sentiment analysis using the Azure OpenAI service. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-01-10T19:14:00.7354446Z",
              "execution_start_time": "2025-01-10T19:13:59.5416787Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "717a471f-e379-4ea2-abb7-0cf76a6677b7",
              "queued_time": "2025-01-10T19:10:28.7962632Z",
              "session_id": "10",
              "session_start_time": "2025-01-10T19:10:28.8266317Z",
              "spark_jobs": null,
              "spark_pool": "default",
              "state": "finished",
              "statement_id": 2,
              "statement_ids": [
                2
              ]
            },
            "text/plain": [
              "StatementMeta(default, 10, 2, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import StructType, StructField, StringType, ArrayType\n",
        "\n",
        "from notebookutils import mssparkutils\n",
        "from string import Template\n",
        "from openai import AzureOpenAI\n",
        "import traceback\n",
        "import httpx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Parameters that are being passed in by the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [
          "parameters"
        ]
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-01-10T19:14:01.1283857Z",
              "execution_start_time": "2025-01-10T19:14:00.9285089Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "d9ee3d77-0c89-459f-ac14-b9f117de52ff",
              "queued_time": "2025-01-10T19:10:28.859431Z",
              "session_id": "10",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "default",
              "state": "finished",
              "statement_id": 3,
              "statement_ids": [
                3
              ]
            },
            "text/plain": [
              "StatementMeta(default, 10, 3, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prompt_file = \"\"\n",
        "openai_service = \"\"\n",
        "openai_deployment = \"\"\n",
        "api_version = \"\"\n",
        "key_vault_url = \"\"\n",
        "secret = \"\"\n",
        "linked_service_name = \"\"\n",
        "data_lake_prompt_path = \"\"\n",
        "data_lake_dataset_path = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Stub for parameters that will be passed in by the pipeline\n",
        "### Sometimes during development, you might want to debug to just work on a notebook without running the whole pipeline.  You will need to uncomment this code block if you are running the notebook outside of the pipeline.  Don't forget to comment it and remove anything you shouldn't have in here before checking in again.  This is here to illustrate that you can run the notebooks outside of the pipeline rather than to demonstrate a best practice :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-01-10T19:21:24.7925677Z",
              "execution_start_time": "2025-01-10T19:21:24.6039096Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "8c20ecda-b2a0-4134-aa79-4d9092e8329d",
              "queued_time": "2025-01-10T19:21:24.4496189Z",
              "session_id": "10",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "default",
              "state": "finished",
              "statement_id": 6,
              "statement_ids": [
                6
              ]
            },
            "text/plain": [
              "StatementMeta(default, 10, 6, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# prompt_file = \"review_prompt.jinja2\"\n",
        "# openai_service = \"\"\n",
        "# openai_deployment = \"gpt-4o\"\n",
        "# api_version = \"2024-10-21\"\n",
        "# key_vault_url = \"\"\n",
        "# secret = \"\"\n",
        "# linked_service_name = \"\"\n",
        "# data_lake_prompt_path = \"****/synapse/prompts/\"\n",
        "# data_lake_dataset_path = \"****/synapse/data/reviews.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Set Variables\n",
        "### We are copying the prompt file from a data lake.  This action happens immediately on the driver, not on one of the worker nodes.\n",
        "### The [mssparkutils](https://learn.microsoft.com/en-us/azure/synapse-analytics/spark/microsoft-spark-utilities?pivots=programming-language-python) utilities library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-01-10T19:21:29.1566002Z",
              "execution_start_time": "2025-01-10T19:21:27.1949753Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "cefbc8a2-afcb-4be8-bc7a-c113e46b951e",
              "queued_time": "2025-01-10T19:21:27.0574352Z",
              "session_id": "10",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "default",
              "state": "finished",
              "statement_id": 7,
              "statement_ids": [
                7
              ]
            },
            "text/plain": [
              "StatementMeta(default, 10, 7, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "system_prompt = \"You are an AI chatbot who determines the sentiment of reviews\"\n",
        "prompt_path = f\"{data_lake_prompt_path}{prompt_file}\"\n",
        "prompt_template = None\n",
        "\n",
        "mssparkutils.fs.cp(prompt_path,f\"file:///tmp/{prompt_file}\")\n",
        "\n",
        "with open(f\"/tmp/{prompt_file}\") as f:\n",
        "    prompt_template = f.read()\n",
        "\n",
        "# Get OpenAI key\n",
        "api_key = mssparkutils.credentials.getSecret(key_vault_url, secret, linked_service_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Create a data frame for the input data\n",
        "### This action is collected by the driver node and executed immediately on the worker nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-01-10T19:21:42.4448106Z",
              "execution_start_time": "2025-01-10T19:21:31.4266751Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "bd9e4729-11d4-4ca1-b045-b724455c6c42",
              "queued_time": "2025-01-10T19:21:31.2842713Z",
              "session_id": "10",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "default",
              "state": "finished",
              "statement_id": 8,
              "statement_ids": [
                8
              ]
            },
            "text/plain": [
              "StatementMeta(default, 10, 8, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = spark.read.load(data_lake_dataset_path, format='csv', header=True, delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Function that calls Azure OpenAI\n",
        "### The function takes the review as a parameter and also passes in parameters required to use the Azure OpenAI SDK\n",
        "- We will be setting this function as a \"user defined function\" in Spark.\n",
        "- The function returns an array of strings, specifically the JSON returned from the Azure OpenAI call and an error value.  If all goes well, we'll have properly formatted JSON in the output value and a value of \"None\" for the error value.\n",
        "- The user prompt is coming from the file we downloaded from our data lake.\n",
        "\n",
        "This is one way to make the Azure OpenAI service call.  There are other libraries that help you do this:\n",
        "- https://microsoft.github.io/SynapseML/docs/Explore%20Algorithms/OpenAI/\n",
        "- https://microsoft.github.io/SynapseML/docs/Explore%20Algorithms/OpenAI/Langchain/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-01-10T19:27:35.33774Z",
              "execution_start_time": "2025-01-10T19:27:35.1455947Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "0ec4e312-d219-41ad-89a8-53e5d0a411f6",
              "queued_time": "2025-01-10T19:27:34.9396233Z",
              "session_id": "10",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "default",
              "state": "finished",
              "statement_id": 9,
              "statement_ids": [
                9
              ]
            },
            "text/plain": [
              "StatementMeta(default, 10, 9, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def get_openai_response(partitionData, endpoint_url=openai_service,deployment=openai_deployment,api_version=api_version, api_key=api_key, prompt=prompt_template, system_prompt=system_prompt):\n",
        "\n",
        "    for row in partitionData:\n",
        "        output = ''\n",
        "        error = ''\n",
        "        user_prompt = Template(prompt).substitute(input=row.review)\n",
        "\n",
        "        #This is actually an APIM Key \n",
        "        http_client = httpx.Client(\n",
        "            headers={\n",
        "                \"Ocp-Apim-Subscription-Key\": api_key\n",
        "            }\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            client = AzureOpenAI(\n",
        "                azure_endpoint = endpoint_url,\n",
        "                api_key= api_key,  #The APIM \n",
        "                api_version= api_version,\n",
        "                http_client=http_client\n",
        "                )\n",
        "\n",
        "            response = client.chat.completions.create(\n",
        "                model=deployment,\n",
        "                response_format = {\"type\": \"json_object\"},\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": user_prompt}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            output = response.choices[0].message.content\n",
        "\n",
        "        except Exception as e:\n",
        "            error = \"\".join(traceback.format_exception(sys.exc_info()[0], sys.exc_info()[1], sys.exc_info()[2]))\n",
        "\n",
        "        yield Row(\n",
        "            row.review\n",
        "            , output\n",
        "            , error\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Call the function \n",
        "### This action is collected by the driver but not executed yet by the worker nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-01-10T19:27:41.0085985Z",
              "execution_start_time": "2025-01-10T19:27:40.8111078Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "609231ca-ac7d-4669-8ffb-6e920a2285d3",
              "queued_time": "2025-01-10T19:27:40.6746458Z",
              "session_id": "10",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "default",
              "state": "finished",
              "statement_id": 11,
              "statement_ids": [
                11
              ]
            },
            "text/plain": [
              "StatementMeta(default, 10, 11, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "report_df = df.repartition(4).rdd.mapPartitions(get_openai_response).toDF([\n",
        "    'review'\n",
        "    , 'output'\n",
        "    , 'error'\n",
        "]).cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Define the JSON schema that will be expanded into the new dataset\n",
        "### This action is collected by the driver but not executed yet by the worker nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-01-10T19:27:49.7841127Z",
              "execution_start_time": "2025-01-10T19:27:49.5782277Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "418a146f-1645-4f84-a952-d22b888d2d78",
              "queued_time": "2025-01-10T19:27:49.4367554Z",
              "session_id": "10",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "default",
              "state": "finished",
              "statement_id": 12,
              "statement_ids": [
                12
              ]
            },
            "text/plain": [
              "StatementMeta(default, 10, 12, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "schema = StructType(\n",
        "    [\n",
        "        StructField('sentiment', StringType(), True),\n",
        "        StructField('rationale', StringType(), True)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Unpack the JSON and create our final dataset\n",
        "### This action is collected by the driver but not executed yet by the worker nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-01-10T19:27:53.3719689Z",
              "execution_start_time": "2025-01-10T19:27:53.1779398Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "e6b4014f-d84b-4e45-b333-5119e260c3b2",
              "queued_time": "2025-01-10T19:27:53.040869Z",
              "session_id": "10",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "default",
              "state": "finished",
              "statement_id": 13,
              "statement_ids": [
                13
              ]
            },
            "text/plain": [
              "StatementMeta(default, 10, 13, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "reviews_df = reviews_df.withColumn(\"data\", from_json(\"output\", schema)).select(col('review'), col('output'), col('error'), col('data.*'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Finally, this action is collected by the driver and executed by the worker nodes.\n",
        "### In a real system you would be saving the data frame to the data lake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "display(reviews_df)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
